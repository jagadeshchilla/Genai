{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPEN_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000025918316650> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025918317550> root_client=<openai.OpenAI object at 0x0000025918315A50> root_async_client=<openai.AsyncOpenAI object at 0x0000025918317700> model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a subset of artificial intelligence techniques that are designed to create new content, data, or information that often mimics or extends existing data. This technology utilizes machine learning models, particularly deep learning, to generate outputs such as text, images, audio, and more.\\n\\nKey characteristics of generative AI include:\\n\\n1. **Model Types**: Generative AI often uses models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer models (e.g., GPT for text, DALL-E for images). Each type has its own methods for generating new content.\\n\\n2. **Applications**: It has a wide range of applications, including:\\n   - **Text Generation**: Creating coherent and contextually relevant text, such as articles, poetry, and conversational agents (chatbots).\\n   - **Image Generation**: Producing realistic images or artworks based on textual descriptions or training data.\\n   - **Music Composition**: Composing new pieces of music in various styles.\\n   - **Video Creation**: Generating video content based on scripts or other forms of input.\\n\\n3. **Training on Data**: Generative AI models are typically trained on large datasets to learn patterns, styles, and structures within the data, enabling them to create new content that retains the statistical properties of the training data.\\n\\n4. **Interactivity**: Many generative AI tools are interactive, allowing users to input prompts or guidelines that influence the output, leading to customizable and personalized content.\\n\\n5. **Ethical Considerations**: The rise of generative AI has prompted discussions about ethics, including concerns about copyright infringement, misinformation, and the potential for misuse in creating deepfakes or other deceptive content.\\n\\nIn summary, generative AI represents a powerful and rapidly evolving area of AI research and application, with the potential to transform various industries by enabling the automatic creation of novel and meaningful content.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 389, 'prompt_tokens': 13, 'total_tokens': 402, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CBewjogWglI4Ff94NTMK3u68E7wFt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--34fb0833-942f-4617-ac54-d787af2b1845-0' usage_metadata={'input_tokens': 13, 'output_tokens': 389, 'total_tokens': 402, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"As of my last knowledge update in October 2023, Langsmith is a company focused on language models and AI-driven solutions. It aims to enhance the development and deployment of language-based applications, leveraging advanced natural language processing techniques. Langsmith might offer tools for improving communication, automating content generation, or analyzing text data.\\n\\nFor the most accurate and updated information, I recommend checking Langsmith's official website or recent news articles, as new developments may have occurred since my last update.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 33, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CBexA9iHcucJ02Ds0sMjpXsNyYji4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--40d53f1b-c182-4a33-b47f-adc048523083-0' usage_metadata={'input_tokens': 33, 'output_tokens': 97, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform that focuses on helping developers create, manage, and optimize large language model (LLM) applications. It provides a collaborative environment that allows teams to work together on language model projects, making it easier to iterate and refine the prompts and outputs generated by these models.\n",
      "\n",
      "Key features often associated with Langsmith include:\n",
      "\n",
      "1. **Prompt Engineering**: Tools to help users craft effective prompts that elicit the desired responses from LLMs.\n",
      "2. **Version Control**: Functionality that enables tracking of changes in prompts and model outputs, facilitating collaboration and experimentation.\n",
      "3. **Performance Insights**: Analytics and metrics that allow users to evaluate the effectiveness of different prompts and models.\n",
      "4. **Team Collaboration**: Features designed for teams to work on LLM applications collectively, sharing insights and best practices.\n",
      "\n",
      "These features help organizations leverage the potential of LLMs more effectively, promoting best practices in AI applications. For the latest information or updates, it's always best to check the official Langsmith website or resources.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
